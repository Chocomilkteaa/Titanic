{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearnex import patch_sklearn\n",
    "\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./Data/train.csv')\n",
    "test_data = pd.read_csv('./Data/test.csv')\n",
    "\n",
    "train_data['Sex'] = train_data['Sex'].map({'male':0, 'female':1})\n",
    "test_data['Sex'] = test_data['Sex'].map({'male':0, 'female':1})\n",
    "\n",
    "label = 'Survived'\n",
    "\n",
    "id = test_data['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    RandomForestClassifier(random_state=0),\n",
    "    GradientBoostingClassifier(random_state=0),\n",
    "    XGBClassifier(random_state=0),\n",
    "    CatBoostClassifier(random_state=0, verbose=0, allow_writing_files=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_parameters = {\n",
    "    'DecisionTree': {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [2, 4, 6, None]\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'n_estimators': [50, 100, 300],\n",
    "        'max_depth': [2, 4, 6, None]\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'learning_rate': [0.2, 0.1, 0.05],\n",
    "        'n_estimators': [50, 100, 300],\n",
    "        'max_depth': [1, 3, 5, None]\n",
    "    },\n",
    "    'xgboost': {\n",
    "        'learning_rate': [0.5, 0.3, 0.1],\n",
    "        'max_depth': [4, 6, 8]\n",
    "    },\n",
    "    'catboost': {\n",
    "        'learning_rate': [0.05, 0.03, 0.01],\n",
    "        'iterations': [300, 500, 800],\n",
    "        'depth': [4, 6, 8]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeOneHot(column, train_data, test_data):\n",
    "    train_data_new = train_data.copy()\n",
    "    test_data_new = test_data.copy()\n",
    "\n",
    "    encoder_onehot = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "    train_data_onehot = encoder_onehot.fit_transform(pd.DataFrame(train_data[column]))\n",
    "    train_feature_name_onehot = encoder_onehot.get_feature_names_out()\n",
    "    train_data_onehot = pd.DataFrame(train_data_onehot, columns=train_feature_name_onehot, dtype=int)\n",
    "\n",
    "    test_data_onehot = encoder_onehot.transform(pd.DataFrame(test_data[column]))\n",
    "    test_data_onehot = pd.DataFrame(test_data_onehot, columns=train_feature_name_onehot, dtype=int)\n",
    "\n",
    "    train_data_new = pd.concat([train_data_new, train_data_onehot], axis=1)\n",
    "    test_data_new = pd.concat([test_data_new, test_data_onehot], axis=1)\n",
    "\n",
    "    train_data_new = train_data_new.drop(column, axis=1)\n",
    "    test_data_new = test_data_new.drop(column, axis=1)\n",
    "\n",
    "    return train_data_new, test_data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(columns_to_drop, label, train_data, test_data):\n",
    "    X_train = train_data.drop([label] + columns_to_drop + ['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "    Y_train = train_data[label]\n",
    "    X_test = test_data.drop(columns_to_drop + ['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "    return X_train, Y_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(models, X_train, Y_train):\n",
    "    model_names = [model.__class__.__name__ for model in models]\n",
    "    model_scores = []\n",
    "\n",
    "    cv = ShuffleSplit(random_state=0)\n",
    "\n",
    "    for model in models:\n",
    "        model = clone(model)\n",
    "        cv_scores = cross_val_score(model, X_train, Y_train, cv=cv)\n",
    "        model_scores.append(cv_scores.mean())\n",
    "\n",
    "    cv_results = pd.DataFrame(columns=['name', 'accuracy_mean'])\n",
    "    cv_results['name'] = model_names\n",
    "    cv_results['accuracy_mean'] = model_scores\n",
    "\n",
    "    return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuneParameters(models, tuning_parameters, X_train, Y_train):\n",
    "    model_names = [model.__class__.__name__ for model in models]\n",
    "    model_scores = []\n",
    "    model_params = []\n",
    "\n",
    "    cv = ShuffleSplit(random_state=0)\n",
    "\n",
    "    for model, params in zip(models, tuning_parameters.items()):\n",
    "        model = clone(model)\n",
    "        tune_model = GridSearchCV(model, param_grid=params[1], scoring='accuracy', cv=cv)\n",
    "        tune_model.fit(X_train, Y_train)\n",
    "        model_scores.append(tune_model.best_score_)\n",
    "        model_params.append(tune_model.best_params_)\n",
    "    \n",
    "    tuning_results = pd.DataFrame(columns=['name', 'best_score', 'best_params'])\n",
    "    tuning_results['name'] = model_names\n",
    "    tuning_results['best_score'] = model_scores\n",
    "    tuning_results['best_params'] = model_params\n",
    "\n",
    "    return tuning_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X_train, Y_train, X_test, id, label, file_name = 'result.csv'):\n",
    "    model = clone(model)\n",
    "    model.fit(X_train, Y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    result = pd.DataFrame({\n",
    "        id.name: id,\n",
    "        label: predictions\n",
    "    })\n",
    "    result.to_csv('./Result/' + file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Pclass', 'Sex', 'SibSp', 'Parch'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = ['Age', 'Fare', 'Embarked']\n",
    "X_train, Y_train, X_test = prepareData(columns_to_drop, label, train_data, test_data)\n",
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         name  accuracy_mean\n",
      "0      DecisionTreeClassifier       0.795556\n",
      "1      RandomForestClassifier       0.796667\n",
      "2  GradientBoostingClassifier       0.813333\n",
      "3               XGBClassifier       0.800000\n",
      "4          CatBoostClassifier       0.810000\n"
     ]
    }
   ],
   "source": [
    "cv_results = evaluation(models, X_train, Y_train)\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         name  best_score  \\\n",
      "0      DecisionTreeClassifier    0.811111   \n",
      "1      RandomForestClassifier    0.821111   \n",
      "2  GradientBoostingClassifier    0.825556   \n",
      "3               XGBClassifier    0.815556   \n",
      "4          CatBoostClassifier    0.826667   \n",
      "\n",
      "                                         best_params  \n",
      "0              {'criterion': 'gini', 'max_depth': 4}  \n",
      "1              {'max_depth': 2, 'n_estimators': 300}  \n",
      "2  {'learning_rate': 0.1, 'max_depth': 1, 'n_esti...  \n",
      "3             {'learning_rate': 0.1, 'max_depth': 4}  \n",
      "4  {'depth': 6, 'iterations': 300, 'learning_rate...  \n"
     ]
    }
   ],
   "source": [
    "tuning_results = tuneParameters(models, tuning_parameters, X_train, Y_train)\n",
    "print(tuning_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state=0, **tuning_results.iloc[0]['best_params'])\n",
    "predict(model, X_train, Y_train, X_test, id, label, 'result_basic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processFare(train_data, test_data):\n",
    "    train_data_new, test_data_new = train_data.copy(), test_data.copy()\n",
    "\n",
    "    feature = 'Fare'\n",
    "    fill_value = train_data_new[feature].mode()[0]\n",
    "    test_data_new[feature] = test_data_new[feature].fillna(value=fill_value)\n",
    "\n",
    "    return train_data_new, test_data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processAge(train_data, test_data):\n",
    "    train_data_new, test_data_new = train_data.copy(), test_data.copy()\n",
    "\n",
    "    feature = 'Age'\n",
    "\n",
    "    age_median_by_pclass = train_data_new[['Pclass', 'Age']].groupby('Pclass').median()\n",
    "\n",
    "    for pclass, row in age_median_by_pclass.iterrows():\n",
    "        train_data_new.loc[(train_data_new['Age'].isnull()) & (train_data_new['Pclass'] == pclass), 'Age'] = row.iloc[0]\n",
    "        test_data_new.loc[(test_data_new['Age'].isnull()) & (test_data_new['Pclass'] == pclass), 'Age'] = row.iloc[0]\n",
    "\n",
    "    return train_data_new, test_data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processEmbarked(train_data, test_data):\n",
    "    train_data_new, test_data_new = train_data.copy(), test_data.copy()\n",
    "\n",
    "    feature = 'Embarked'\n",
    "    fill_value = train_data_new[feature].mode()[0]\n",
    "    train_data_new[feature] = train_data_new[feature].fillna(value=fill_value)\n",
    "    test_data_new[feature] = test_data_new[feature].fillna(value=fill_value)\n",
    "\n",
    "    train_data_new, test_data_new = makeOneHot('Embarked', train_data_new, test_data_new)\n",
    "\n",
    "    return train_data_new, test_data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processTitle(train_data, test_data):\n",
    "    train_data_new, test_data_new = train_data.copy(), test_data.copy()\n",
    "\n",
    "    feature = 'Title'\n",
    "\n",
    "    def process(name):\n",
    "        new_feature = name.str.extract(r' ([A-Za-z]+)\\.', expand=False)\n",
    "        new_feature = new_feature.replace({'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs'})\n",
    "        new_feature = new_feature.replace(['Lady', 'Countess','Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "        \n",
    "        return new_feature\n",
    "    \n",
    "    train_data_new[feature] = process(train_data_new['Name'])\n",
    "    test_data_new[feature] = process(test_data_new['Name'])\n",
    "\n",
    "    train_data_new, test_data_new = makeOneHot(feature, train_data_new, test_data_new)\n",
    "\n",
    "    return train_data_new, test_data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processFamily(train_data, test_data):\n",
    "    train_data_new, test_data_new = train_data.copy(), test_data.copy()\n",
    "\n",
    "    train_data_new['Family'] = train_data_new['SibSp'] + train_data_new['Parch'] + 1\n",
    "    test_data_new['Family'] = test_data_new['SibSp'] + test_data_new['Parch'] + 1\n",
    "\n",
    "    return train_data_new, test_data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processAlone(train_data, test_data):\n",
    "    train_data_new, test_data_new = processFamily(train_data, test_data)\n",
    "\n",
    "    train_data_new['Alone'] = train_data_new['Family'].apply(lambda x: 1 if x == 1 else 0)\n",
    "    test_data_new['Alone'] = test_data_new['Family'].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "    return train_data_new, test_data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processFareBin(train_data, test_data):\n",
    "    train_data_new, test_data_new = train_data.copy(), test_data.copy()\n",
    "\n",
    "    feature = 'Fare'\n",
    "    new_feature = 'FareBinned'\n",
    "\n",
    "    fill_value = train_data[feature].mode()[0]\n",
    "    test_data_new[feature] = test_data_new[feature].fillna(value=fill_value)\n",
    "\n",
    "    train_data_new[new_feature], bins = pd.qcut(train_data_new[feature], 5, labels=[0,1,2,3,4], retbins=True)\n",
    "    train_data_new[new_feature] = train_data_new[new_feature].astype(int)\n",
    "\n",
    "    def bin(x):\n",
    "        if x < bins[1]:\n",
    "            return 0\n",
    "        elif x < bins[2]:\n",
    "            return 1\n",
    "        elif x < bins[3]:\n",
    "            return 2\n",
    "        elif x < bins[4]:\n",
    "            return 3\n",
    "        else:\n",
    "            return 4\n",
    "\n",
    "    test_data_new[new_feature] = test_data_new[feature].apply(bin)\n",
    "\n",
    "    return train_data_new, test_data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Age\n",
       "Pclass      \n",
       "1       37.0\n",
       "2       29.0\n",
       "3       24.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_median_by_pclass = train_data[['Pclass', 'Age']].groupby('Pclass').median()\n",
    "age_median_by_pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processAgeBin(train_data, test_data):\n",
    "    train_data_new, test_data_new = train_data.copy(), test_data.copy()\n",
    "\n",
    "    feature = 'Age'\n",
    "    new_feature = 'AgeBinned'\n",
    "\n",
    "    age_median_by_pclass = train_data_new[['Pclass', 'Age']].groupby('Pclass').median()\n",
    "\n",
    "    for pclass, row in age_median_by_pclass.iterrows():\n",
    "        train_data_new.loc[(train_data_new['Age'].isnull()) & (train_data_new['Pclass'] == pclass), 'Age'] = row.iloc[0]\n",
    "        test_data_new.loc[(test_data_new['Age'].isnull()) & (test_data_new['Pclass'] == pclass), 'Age'] = row.iloc[0]\n",
    "\n",
    "    train_data_new[new_feature], bins = pd.qcut(train_data_new[feature], 5, labels=[0,1,2,3,4], retbins=True)\n",
    "    train_data_new[new_feature] = train_data_new[new_feature].astype(int)\n",
    "\n",
    "    def bin(x):\n",
    "        if x < bins[1]:\n",
    "            return 0\n",
    "        elif x < bins[2]:\n",
    "            return 1\n",
    "        elif x < bins[3]:\n",
    "            return 2\n",
    "        elif x < bins[4]:\n",
    "            return 3\n",
    "        else:\n",
    "            return 4\n",
    "\n",
    "    test_data_new[new_feature] = test_data_new[feature].apply(bin)\n",
    "\n",
    "    return train_data_new, test_data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processAgeMinor(train_data, test_data):\n",
    "    train_data_new, test_data_new = processAge(train_data, test_data)\n",
    "\n",
    "    feature = 'Age'\n",
    "    new_feature = 'AgeMinor'\n",
    "    minorAge = 16\n",
    "    train_data_new[new_feature] = (train_data_new[feature] < minorAge).astype(int)\n",
    "    test_data_new[new_feature] = (test_data_new[feature] < minorAge).astype(int)\n",
    "\n",
    "    return train_data_new, test_data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processTicketNumber(train_data, test_data):\n",
    "    train_data_new, test_data_new = train_data.copy(), test_data.copy()\n",
    "\n",
    "    def get_ticket_number(ticket):\n",
    "        num = ticket.split(' ')[-1]\n",
    "        if num.isdigit():\n",
    "            return int(num)\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "    train_data_new['TicketNumber'] = train_data_new['Ticket'].apply(get_ticket_number)\n",
    "    test_data_new['TicketNumber'] = test_data_new['Ticket'].apply(get_ticket_number)\n",
    "\n",
    "\n",
    "    return train_data_new, test_data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processSurvivedGroup(train_data, test_data):\n",
    "    train_data_new, test_data_new = processTicketNumber(train_data, test_data)\n",
    "\n",
    "    train_data_new['SurvivedGroup'] = 0.5\n",
    "    test_data_new['SurvivedGroup'] = 0.5\n",
    "\n",
    "    survive_mean_by_ticketnum = train_data_new[['TicketNumber', 'Survived']].groupby(['TicketNumber']).mean()\n",
    "\n",
    "    for ticketnum, row in survive_mean_by_ticketnum.iterrows():\n",
    "        train_data_new.loc[train_data_new['TicketNumber'] == ticketnum, 'SurvivedGroup'] = row.iloc[0]\n",
    "        test_data_new.loc[test_data_new['TicketNumber'] == ticketnum, 'SurvivedGroup'] = row.iloc[0]\n",
    "\n",
    "    return train_data_new, test_data_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_new, test_data_new = processFare(train_data, test_data)\n",
    "train_data_new, test_data_new = processAge(train_data_new, test_data_new)\n",
    "train_data_new, test_data_new = processEmbarked(train_data_new, test_data_new)\n",
    "train_data_new, test_data_new = processTitle(train_data_new, test_data_new)\n",
    "train_data_new, test_data_new = processFamily(train_data_new, test_data_new)\n",
    "train_data_new, test_data_new = processAlone(train_data_new, test_data_new)\n",
    "train_data_new, test_data_new = processFareBin(train_data_new, test_data_new)\n",
    "train_data_new, test_data_new = processAgeBin(train_data_new, test_data_new)\n",
    "train_data_new, test_data_new = processAgeMinor(train_data_new, test_data_new)\n",
    "train_data_new, test_data_new = processTicketNumber(train_data_new, test_data_new)\n",
    "train_data_new, test_data_new = processSurvivedGroup(train_data_new, test_data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_C',\n",
      "       'Embarked_Q', 'Embarked_S', 'Title_Master', 'Title_Miss', 'Title_Mr',\n",
      "       'Title_Mrs', 'Title_Rare', 'Family', 'Alone', 'FareBinned', 'AgeBinned',\n",
      "       'AgeMinor', 'TicketNumber', 'SurvivedGroup'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = []\n",
    "X_train, Y_train, X_test = prepareData(columns_to_drop, label, train_data_new, test_data_new)\n",
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass 6\n",
      "Sex 2\n",
      "Age 5\n",
      "SibSp 11\n",
      "Parch 13\n",
      "Fare 3\n",
      "Embarked_C 17\n",
      "Embarked_Q 20\n",
      "Embarked_S 15\n",
      "Title_Master 14\n",
      "Title_Miss 9\n",
      "Title_Mr 1\n",
      "Title_Mrs 8\n",
      "Title_Rare 19\n",
      "Family 7\n",
      "Alone 16\n",
      "FareBinned 10\n",
      "AgeBinned 12\n",
      "AgeMinor 18\n",
      "TicketNumber 4\n",
      "SurvivedGroup 1\n"
     ]
    }
   ],
   "source": [
    "cv = ShuffleSplit(random_state=0)\n",
    "model = RandomForestClassifier(random_state=0)\n",
    "selector = RFECV(estimator=model, cv=cv, scoring='accuracy')\n",
    "selector.fit(X_train, Y_train)\n",
    "\n",
    "for feature, rank in zip(X_train.columns, selector.ranking_):\n",
    "    print(feature, rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         name  accuracy_mean\n",
      "0      DecisionTreeClassifier       0.980000\n",
      "1      RandomForestClassifier       0.985556\n",
      "2  GradientBoostingClassifier       0.978889\n",
      "3               XGBClassifier       0.975556\n",
      "4          CatBoostClassifier       0.977778\n"
     ]
    }
   ],
   "source": [
    "columns_selected = ['SurvivedGroup', 'Sex', 'FareBinned', 'AgeMinor', 'Pclass']\n",
    "cv_results = evaluation(models, X_train[columns_selected], Y_train)\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         name  best_score  \\\n",
      "0      DecisionTreeClassifier    0.982222   \n",
      "1      RandomForestClassifier    0.985556   \n",
      "2  GradientBoostingClassifier    0.982222   \n",
      "3               XGBClassifier    0.981111   \n",
      "4          CatBoostClassifier    0.981111   \n",
      "\n",
      "                                         best_params  \n",
      "0              {'criterion': 'gini', 'max_depth': 4}  \n",
      "1               {'max_depth': 6, 'n_estimators': 50}  \n",
      "2  {'learning_rate': 0.2, 'max_depth': 1, 'n_esti...  \n",
      "3             {'learning_rate': 0.1, 'max_depth': 4}  \n",
      "4  {'depth': 4, 'iterations': 300, 'learning_rate...  \n"
     ]
    }
   ],
   "source": [
    "tuning_results = tuneParameters(models, tuning_parameters, X_train[columns_selected], Y_train)\n",
    "print(tuning_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=0, **tuning_results.iloc[1]['best_params'])\n",
    "predict(model, X_train[columns_selected], Y_train, X_test[columns_selected], id, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train_data, test_data], axis=0)\n",
    "\n",
    "data['Fare_5'] = pd.qcut(data.Fare, 5, labels=[0, 1, 2, 3, 4]).astype(int)\n",
    "\n",
    "data['Survival_group'] = 0.5\n",
    "\n",
    "for _, group in data.groupby('Ticket'):\n",
    "    if(len(group) > 1):\n",
    "        for index, row in group.iterrows():\n",
    "            smax = group.drop(index)['Survived'].max()\n",
    "            smin = group.drop(index)['Survived'].min()\n",
    "            id = row['PassengerId']\n",
    "            if(smax == 1.0):\n",
    "                data.loc[data['PassengerId'] == id, 'Survival_group'] = 1.0\n",
    "            elif(smin == 0.0):\n",
    "                data.loc[data['PassengerId'] == id, 'Survival_group'] = 0.0\n",
    "\n",
    "data['Title'] = data['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\n",
    "data['Title'] = data['Title'].replace(['Capt', 'Col', 'Countess', 'Don', 'Dr', 'Dona', 'Jonkheer', 'Major', 'Rev', 'Sir'], 'Rare')\n",
    "data['Title'] = data['Title'].replace(['Mlle', 'Ms', 'Mme'], 'Miss')\n",
    "data['Title'] = data['Title'].replace(['Lady'], 'Mrs')\n",
    "\n",
    "age_median = data.groupby('Title')['Age'].median().values\n",
    "data['Age_group'] = data['Age']\n",
    "\n",
    "data['Title_enc'] = data['Title'].map({'Mr': 0, 'Rare': 1, 'Master': 2, 'Miss': 3, 'Mrs': 4}).astype(int)\n",
    "for i in range(0, 5):\n",
    "    data.loc[(data['Age'].isnull())&(data['Title_enc']==i), 'Age_group'] = age_median[i]\n",
    "\n",
    "data['Age_minor'] = (data['Age_group'] < 16.0).astype(int)\n",
    "\n",
    "train = data[:len(train_data)]\n",
    "test = data[len(train_data):]\n",
    "\n",
    "features = ['Pclass', 'Sex_b', 'Fare_5_enc', 'Survival_group', 'Age_minor']\n",
    "\n",
    "model = RandomForestClassifier(random_state=2, n_estimators=250, min_samples_split=20, oob_score=True)\n",
    "model.fit(train[features], train['Survived'])\n",
    "\n",
    "predictions = pd.DataFrame(model.predict(test[features]))\n",
    "\n",
    "result = pd.concat([test.PassengerId, predictions], axis=1)\n",
    "result.columns = ['PassengerId', 'Survived']\n",
    "\n",
    "result.to_csv('./result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
